{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General setup, as explained earlier\n",
    "import os\n",
    "from pprint import pprint\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "PLANET_API_URL = 'https://api.planet.com/data/v1'\n",
    "\n",
    "def setup_session(api_key=None):\n",
    "    \"\"\"\n",
    "    Initialize a requests.Session that handles Planet api key auth and retries.\n",
    "    \n",
    "    :param str api_key:\n",
    "        A Planet api key. Will be read from the PL_API_KEY env var if not specified.\n",
    "    \n",
    "    :returns requests.Session session:\n",
    "        A Session instance optimized for use with Planet's api.\n",
    "    \"\"\"\n",
    "    if api_key is None:\n",
    "        api_key = os.getenv('PL_API_KEY')\n",
    "\n",
    "    session = requests.Session()\n",
    "    session.auth = (api_key, '')\n",
    "\n",
    "    retries = Retry(total=5,\n",
    "                    backoff_factor=0.2,  \n",
    "                    status_forcelist=[429])\n",
    "\n",
    "    session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "    return session\n",
    "\n",
    "session = setup_session() # Or pass in an api key if the environment variable isn't set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, but how do I download data?\n",
    "---------------------------------------------------\n",
    "\n",
    "Okay, we've talked a lot about how to search for data, so let's finally start retrieving data.\n",
    "\n",
    "Downloading data in the Planet API is a 2-step process. We need to first \"activate\" the asset before we can download it.  \n",
    "\n",
    "Behind the scenes, this is because we don't store what you download in its full, ready-to-use form.  We store a much more low-level form of the data that can be processed to multiple different asset types.  However, this takes a few minutes of compute time.\n",
    "\n",
    "Let's work with a scene you should have permission to download assets for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = '20180227_181938_1042'\n",
    "itemtype = 'PSScene4Band'\n",
    "\n",
    "url = '{}/item-types/{}/items/{}'.format(PLANET_API_URL, itemtype, scene)\n",
    "response = session.get(url)\n",
    "response.raise_for_status()\n",
    "info = response.json()\n",
    "\n",
    "# Just for fun, let's display the thumbnail:\n",
    "from IPython.display import Image\n",
    "Image(session.get(info['_links']['thumbnail']).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now let's look at the response we got from the API in more detail:\n",
    "pprint(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you'll see `download` permissions in the `_permissions` section.\n",
    "\n",
    "Activation\n",
    "---------------\n",
    "\n",
    "We looked at what the `assets` url (in `_links`) returned briefly in section 2. Let's look at it in more detail now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_url = info['_links']['assets']\n",
    "\n",
    "res = session.get(assets_url)\n",
    "res.raise_for_status()\n",
    "assets = res.json()\n",
    "\n",
    "pprint(assets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's a bit hard to read... Let's take a look at the structure for a single asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(assets['analytic_sr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we see `'download'` in the `_permissions` list.  Also note the `status` -- it's \"inactive\".  This means we need to activate the scene before we can download it.\n",
    "\n",
    "To activate the scene, follow the `activate` url in the `_links` section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = session.get(assets['analytic_sr']['_links']['activate'])\n",
    "response.raise_for_status()\n",
    "\n",
    "# Let's have a closer look at the actual response code\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we've requested that the scene be activated.  Behind the scenes, a bunch of work is happening to turn the low-level data we store into something usable.  Why did we inspect the response code, though?\n",
    "\n",
    "### Activation Response Codes\n",
    "\n",
    "After hitting an activation url, you should get a response code back from the API:\n",
    "\n",
    "* **`202`** - The request has been accepted and the activation will begin shortly. \n",
    "* **`204`** - The asset is already active and no further action is needed. \n",
    "* **`401`** - The user does not have permissions to download this file.\n",
    "\n",
    "You can also get the same information by inspecting the `status` of the asset. The categories are `inactive`, `activating`, and `active`.\n",
    "\n",
    "Waiting\n",
    "-----------\n",
    "\n",
    "We can't download the scene until it's active, as indicated by a 204 response code or `status: active`.  We could just wait around a few minutes, but let's automate the waiting.  (In other words, let's poll the api...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "asset_name = 'analytic_sr'\n",
    "assets_url = info['_links']['assets'] # From our earlier request\n",
    "\n",
    "# We could also construct this if needed\n",
    "print(assets_url)\n",
    "\n",
    "while True:\n",
    "    # Send a request to the assets url for this item + scene:\n",
    "    res = session.get(assets_url)\n",
    "    res.raise_for_status()\n",
    "    assets = res.json()\n",
    "\n",
    "    if assets[asset_name]['status'] == 'active':\n",
    "        print(\"Asset is active and ready to download\")\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(0.5)\n",
    "\n",
    "# Print the asset data    \n",
    "pprint(assets[asset_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay! Great! We're ready to download now!\n",
    "\n",
    "Downloading\n",
    "-------------------\n",
    "\n",
    "Note the `location` that's now in the response for our asset.  That's what we'll follow to download the data.  However, we'll also need to take a look at its headers to determine what filename we should use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url = assets[asset_name]['location']\n",
    "\n",
    "# We don't want to download the full thing all at once, so we'll stream it\n",
    "response = session.get(download_url, stream=True)\n",
    "response.raise_for_status()\n",
    "\n",
    "pprint(response.headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of clutter there but it's standard if you're familiar with what request headers look like.  If you're not, the parts we want to look at are `Content-Disposition` and possibly `Content-Type` and `Content-Length`.\n",
    "\n",
    "The `Content-Disposition` header tells us what name we should save the file as (by default, anyway -- you can do whatever you'd like).  The others let us know what type of file it is (in very broad terms) and its size (in bytes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disposition = response.headers['Content-Disposition']\n",
    "filetype = response.headers['Content-Type']\n",
    "size = response.headers['Content-Length']\n",
    "\n",
    "mb_size = int(size) / 1024**2\n",
    "\n",
    "print('This is a {:.1f}MB {} file'.format(mb_size, filetype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a bit of a closer look at the content disposition header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(disposition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the actual filename, we'll use a regex. If you're not familiar with regular expressions, this will find what's inside the quotes with `filename=\"foo\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "filename = re.findall(r'filename=\"(.+)\"', disposition)[0]\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay! On to actually downloading the file!\n",
    "\n",
    "Remember the file size? This is over 100MB.  Therefore, it's best not to download it at once.  Instead, we'll download it in chunks.  Fortunately, python has some builtin functions that can do this for us so we don't need to iterate over 1KB at a time.\n",
    "\n",
    "Let's repeat what we did before to start bringing things together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "download_url = assets[asset_name]['location']\n",
    "\n",
    "# We don't want to download the full thing all at once, so we'll stream it\n",
    "response = session.get(download_url, stream=True)\n",
    "response.raise_for_status()\n",
    "\n",
    "disposition = response.headers['Content-Disposition']\n",
    "filename = re.findall(r'filename=\"(.+)\"', disposition)[0]\n",
    "\n",
    "# shutil.copyfileobj will download this in chunks. You can do it manually if you prefer.\n",
    "with open(filename, 'wb') as outfile:\n",
    "    shutil.copyfileobj(response.raw, outfile)\n",
    "del response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double-check that it really did download the full thing (The `!` escapes to a shell in a notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -lh *.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll skip working with the file -- that's for other workshops.  Let's move on to tying this back in to the searches we were doing earlier.\n",
    "\n",
    "---\n",
    "\n",
    "Activating and Download Search Results\n",
    "--------------------------------------\n",
    "\n",
    "We've spent a lot of time laying the low-level framework. Now let's walk through one of the most common tasks you'd want to use our api for.  We'll query for scenes using the quick-search endpoint and a JSON filter definition to define the search.  Then we'll iterate through the results (using pagination if needed) and activate each item.  We'll wait for the items to become active and then we'll download them.\n",
    "\n",
    "Again, note that there are lots of higher-level tools to do this more easily: e.g. `planet data download` in the cli tool or interactively using https://planet.com/explorer.  The point of this workshop is to show the API that those tools are using \"under-the-hood\".\n",
    "\n",
    "This is also where we're going to start using more Python. If you're not familiar with Python, don't stress -- focus on the high level aspects.  Again, the steps are:\n",
    "\n",
    "  1. Search for scenes\n",
    "  2. Activate the asset(s) you want for those scenes\n",
    "  3. Wait for them to become active\n",
    "  4. Download the files for each scene/asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(geom, start_date, end_date, item_type, asset):\n",
    "    \"\"\"\n",
    "    Query the Planet api for scenes overlapping an AOI within a TOI that \n",
    "    have the specified asset.\n",
    "    \n",
    "    :param dict geom:  A geojson geometry\n",
    "    :param str start_date: An iso-8601-formatted timestamp in UTC (earliest scenes)\n",
    "    :param str end_date: An iso-8601-formatted timestamp in UTC (latest scenes)\n",
    "    :param str item_type: A single item type name (e.g. PSScene4Band)\n",
    "    :param str asset: The asset name we're going to use.\n",
    "    \"\"\"\n",
    "    # First let's filter for scenes where we have download permissions. This\n",
    "    # serves two purposes: 1) avoid scenes that do not have the asset we want, \n",
    "    # and 2) avoid scenes we don't have access to.\n",
    "    perm_filter = {\n",
    "      \"type\": \"PermissionFilter\",\n",
    "      \"config\": [\"assets.{}:download\".format(asset)]\n",
    "    }\n",
    "\n",
    "    # Then we'll filter for our AOI \n",
    "    geom_filter = {\n",
    "      \"type\": \"GeometryFilter\",\n",
    "      \"field_name\": \"geometry\",\n",
    "      \"config\": geom\n",
    "    }\n",
    "    \n",
    "    # And the TOI\n",
    "    date_filter = {\n",
    "      \"type\": \"DateRangeFilter\",\n",
    "      \"field_name\": \"acquired\",\n",
    "      \"config\": {\n",
    "        \"gt\": start_date,\n",
    "        \"lte\": end_date\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    # Then combine the three\n",
    "    and_filter = {\n",
    "      \"type\": \"AndFilter\",\n",
    "      \"config\": [perm_filter, geom_filter, date_filter]\n",
    "    }\n",
    "    \n",
    "    request = {\n",
    "      \"item_types\" : [item_type],\n",
    "      \"filter\" : and_filter\n",
    "    }\n",
    "    \n",
    "    resp = session.post(\"{}/quick-search\".format(PLANET_API_URL), json=request)\n",
    "    resp.raise_for_status()\n",
    "    body = resp.json()\n",
    "    \n",
    "    for item in body['features']:\n",
    "        yield item\n",
    "    \n",
    "    next_url = body['_links'].get('_next')\n",
    "    while next_url:\n",
    "        response = session.get(next_url)\n",
    "        response.raise_for_status()\n",
    "        body = response.json()\n",
    "        next_url = body['_links'].get('_next')\n",
    "        for item in body['features']:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your accounts for this exercise should have access to download data in California between October 2017 through the end of March 2018.  Feel free to substitue different AOIs and Dates here! (go to http://geojson.io to draw a different geometry if you'd like)\n",
    "\n",
    "For now, we'll just print the names of the scenes we find:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [\n",
    "          [\n",
    "            [\n",
    "              -119.68505859375,\n",
    "              35.131702190832634\n",
    "            ],\n",
    "            [\n",
    "              -119.60248947143555,\n",
    "              35.06611364116525\n",
    "            ],\n",
    "            [\n",
    "              -119.57914352416992,\n",
    "              35.07679117524852\n",
    "            ],\n",
    "            [\n",
    "              -119.6714973449707,\n",
    "              35.14026553479837\n",
    "            ],\n",
    "            [\n",
    "              -119.68505859375,\n",
    "              35.131702190832634\n",
    "            ]\n",
    "          ]\n",
    "        ]\n",
    "      }\n",
    "\n",
    "asset = 'visual'\n",
    "results = search(geom, '2018-01-01T00:00:00Z', '2018-01-10T00:00:00Z', 'PSScene3Band', asset)\n",
    "\n",
    "# That's a generator. Let's expand it to a list to make it easier to reuse these results later\n",
    "results = list(results)\n",
    "\n",
    "for feature in results:\n",
    "    print(feature['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's move on to the next step - Activation of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetch_assets(feature):\n",
    "    # Fetch the assets section\n",
    "    assets_url = feature['_links']['assets']\n",
    "    resp = session.get(assets_url)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()\n",
    "\n",
    "def activate(results, asset_name):\n",
    "    \"\"\"Activate the results of a search.\"\"\"\n",
    "    for feature in results:\n",
    "        assets = _fetch_assets(feature)\n",
    "        \n",
    "        if assets[asset_name]['status'] == 'inactive':\n",
    "            response = session.get(assets[asset_name]['_links']['activate'])\n",
    "            response.raise_for_status()\n",
    "\n",
    "# This will be fairly quick...    \n",
    "activate(results, asset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to wait on things to become active.  This can take awhile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_active(results, asset_name):\n",
    "    \"\"\"Wait for all results in a search to become active\"\"\"\n",
    "    active = [False]\n",
    "    \n",
    "    while not all(active):\n",
    "        # Getting just a touch fancier with Python. If you're not familiar with it, this is a for loop\n",
    "        statuses = [_fetch_assets(item)[asset_name]['status'] for item in results]\n",
    "        \n",
    "        active = [item == 'active' for item in statuses]\n",
    "\n",
    "# May take awhile...\n",
    "wait_for_active(results, asset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we'll download the files!  This might take a bit... We could do this asychronously as well. It's only a few more lines of code, but requires a bit more familiarity with Python, so we'll leave the parallelizing this out for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(results, asset_name):\n",
    "    for feature in results:\n",
    "        assets = _fetch_assets(feature)\n",
    "        download_url = assets[asset_name]['location']\n",
    "\n",
    "        # We don't want to download the full thing all at once, so we'll stream it\n",
    "        response = session.get(download_url, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Figure out what we should call the local file\n",
    "        disposition = response.headers['Content-Disposition']\n",
    "        filename = re.findall(r'filename=\"(.+)\"', disposition)[0]\n",
    "        print('Downloading {}'.format(filename))\n",
    "\n",
    "        # Download in chunks.\n",
    "        with open(filename, 'wb') as outfile:\n",
    "            shutil.copyfileobj(response.raw, outfile)\n",
    "        del response\n",
    "        \n",
    "        yield filename\n",
    "\n",
    "files = list(download(results, asset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
